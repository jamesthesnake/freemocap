{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# this is Jon's attempt to put Karl's `alignPupilFMC.py` into an jupyter notebook   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install pyqt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    %matplotlib qt\n",
    "    # %matplotlib \n",
    "    import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### get yr paths right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session_id = 'sesh_2022-02-15_11_54_28_pupil_maybe'\n",
    "freemocap_data_folder = Path('C:/Users/jonma/Dropbox/FreeMoCapProject/FreeMocap_Data')\n",
    "\n",
    "session_folder_path = freemocap_data_folder / session_id\n",
    "\n",
    "mediapipe_skeleton_data_path = session_folder_path / 'DataArrays'/ 'mediaPipeSkel_3d_smoothed.npy'\n",
    "mediapipe_head_rotations_path = session_folder_path / 'DataArrays'/ 'mediaPipeSkel_3d_head_rotation_matricies_fr_row_col.npy'\n",
    "\n",
    "pupil_data_path = session_folder_path / 'pupil_000'\n",
    "pupil_data_exports_path = pupil_data_path / 'exports' / '000'\n",
    "pupil_positions_path = pupil_data_exports_path / 'pupil_positions.csv'\n",
    "pupil_recording_info_path = pupil_data_path / 'info.player.json'\n",
    "\n",
    "freemocap_unix_timestamp_path = session_folder_path /'unix_synced_timestamps.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ### load in data\n",
    "\n",
    "- full body 3d kinematic data - `mediapipe_skeleton_frame_mar_xyz`\n",
    "    - type: numpy array\n",
    "    - dimensions: [frame_number, tracked_point_number, dimension (xyz)]\n",
    "- pupil data from `pupil_positions.csv` in the **pupil exports** folder\n",
    "    - definitions in `pupil_gaze_positions_info.txt`\n",
    "- pupil start time from `info.player.json` for sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mediapipe_skeleton_fr_mar_xyz = np.load(mediapipe_skeleton_data_path)\n",
    "mediapipe_head_rotation_matricies_fr_row_col = np.load(mediapipe_head_rotations_path)\n",
    "pupil_dataframe = pd.read_csv(pupil_positions_path)\n",
    "pupil_recording_info_json = json.load(open(pupil_recording_info_path))\n",
    "freemocap_unix_timestamps_dataframe = pd.read_csv(freemocap_unix_timestamp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### pull out relevant pupil data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "data for both eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "timestamps = np.array(pupil_dataframe['pupil_timestamp'])\n",
    "eye_theta = np.array(pupil_dataframe['theta'])\n",
    "eye_phi = np.array(pupil_dataframe['phi'])\n",
    "sphere_center_x = np.array(pupil_dataframe['sphere_center_x'])\n",
    "sphere_center_y = np.array(pupil_dataframe['sphere_center_y'])\n",
    "sphere_center_z = np.array(pupil_dataframe['sphere_center_z'])\n",
    "pupil_center_normal_x = np.array(pupil_dataframe['circle_3d_normal_x'])\n",
    "pupil_center_normal_y = np.array(pupil_dataframe['circle_3d_normal_y'])\n",
    "pupil_center_normal_z = np.array(pupil_dataframe['circle_3d_normal_z'])\n",
    "\n",
    "eye_d = pupil_dataframe['eye_id']\n",
    "method = pupil_dataframe['method']\n",
    "# tracking_method_name = 'pye3d 0.3.0 real-time'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "get data for the right eye\n",
    "\n",
    "pull out data according to `eye_d` (right_eye == 0) and tracking method (because pupil interleaves 2d and 3d data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "right_eye_d = 0 \n",
    "\n",
    "#timestamps\n",
    "r_eye_timestamps_og = timestamps[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n",
    "\n",
    "r_eye_theta = eye_theta[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n",
    "r_eye_phi = eye_phi[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n",
    "\n",
    "r_eye_sphere_center_x = sphere_center_x[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n",
    "r_eye_sphere_center_y = sphere_center_y[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n",
    "r_eye_sphere_center_z = sphere_center_z[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n",
    "\n",
    "r_eye_pupil_center_normal_x = pupil_center_normal_x[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n",
    "r_eye_pupil_center_normal_y = pupil_center_normal_y[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n",
    "r_eye_pupil_center_normal_z = pupil_center_normal_z[np.logical_and(eye_d==right_eye_d, method!='2d c++')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get data for the left eye\n",
    "\n",
    "pull out data according to `eye_d` (left eye == 1) and tracking method (because pupil interleaves 2d and 3d data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "left_eye_d = 1 \n",
    "\n",
    "#timestamps\n",
    "l_eye_timestamps_og = timestamps[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n",
    "\n",
    "l_eye_theta = eye_theta[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n",
    "l_eye_phi = eye_phi[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n",
    "\n",
    "l_eye_sphere_center_x = sphere_center_x[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n",
    "l_eye_sphere_center_y = sphere_center_y[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n",
    "l_eye_sphere_center_z = sphere_center_z[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n",
    "\n",
    "l_eye_pupil_center_normal_x = pupil_center_normal_x[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n",
    "l_eye_pupil_center_normal_y = pupil_center_normal_y[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n",
    "l_eye_pupil_center_normal_z = pupil_center_normal_z[np.logical_and(eye_d==left_eye_d, method!='2d c++')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    fig = plt.figure(num=2134,figsize=(10,10))\n",
    "    \n",
    "    ax1 = fig.add_subplot(321)\n",
    "    ax1.plot(r_eye_timestamps_og, r_eye_theta, '.-', label='r eye theta')\n",
    "    ax1.plot(r_eye_timestamps_og, r_eye_phi, '.-', label='r eye phi')\n",
    "\n",
    "    ax1.legend(loc='upper right')\n",
    "    \n",
    "    ax3 = fig.add_subplot(323)\n",
    "    ax3.plot(r_eye_timestamps_og, r_eye_pupil_center_normal_x, '.-', label='r_eye_pupil_center_normal_x')\n",
    "    ax3.plot(r_eye_timestamps_og, r_eye_pupil_center_normal_y, '.-', label='r_eye_pupil_center_normal_y')\n",
    "    ax3.plot(r_eye_timestamps_og, r_eye_pupil_center_normal_z, '.-', label='r_eye_pupil_center_normal_z')\n",
    "    ax3.legend(loc='upper right')\n",
    "\n",
    "    ax5 = fig.add_subplot(325)\n",
    "    ax5.plot(r_eye_timestamps_og, r_eye_sphere_center_x, '.-', label='r_eye_sphere_center_x')\n",
    "    ax5.plot(r_eye_timestamps_og, r_eye_sphere_center_y, '.-', label='r_eye_sphere_center_y')\n",
    "    ax5.plot(r_eye_timestamps_og, r_eye_sphere_center_z, '.-', label='r_eye_sphere_center_z')\n",
    "    ax5.legend(loc='upper right')\n",
    "\n",
    "    \n",
    "    ax2 = fig.add_subplot(322)\n",
    "    ax2.plot(l_eye_timestamps_og, l_eye_theta, '.-', label='l eye theta')\n",
    "    ax2.plot(l_eye_timestamps_og, l_eye_phi, '.-', label='l eye phi')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    ax4 = fig.add_subplot(324)\n",
    "    ax4.plot(l_eye_timestamps_og, l_eye_pupil_center_normal_x, '.-', label='l_eye_pupil_center_normal_x')\n",
    "    ax4.plot(l_eye_timestamps_og, l_eye_pupil_center_normal_y, '.-', label='l_eye_pupil_center_normal_y')\n",
    "    ax4.plot(l_eye_timestamps_og, l_eye_pupil_center_normal_z, '.-', label='l_eye_pupil_center_normal_z')\n",
    "    ax4.legend(loc='upper right')\n",
    "\n",
    "    ax6 = fig.add_subplot(326)\n",
    "    ax6.plot(l_eye_timestamps_og, l_eye_sphere_center_x, '.-', label='l_eye_sphere_center_x')\n",
    "    ax6.plot(l_eye_timestamps_og, l_eye_sphere_center_y, '.-', label='l_eye_sphere_center_y')\n",
    "    ax6.plot(l_eye_timestamps_og, l_eye_sphere_center_z, '.-', label='l_eye_sphere_center_z')\n",
    "\n",
    "    plt.pause(.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### create XYZ gaze array\n",
    "\n",
    "\n",
    "subtract eyeball center from pupil center to re-base the gaze vector to the origin  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "skipping 'remove nans' step for now, but i might need to add it later? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### synchronize pupil and freemocap timestamps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### convert pupil timestamps into unix time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r_eye_timestamps =  r_eye_timestamps_og - pupil_recording_info_json['start_time_synced_s'] +pupil_recording_info_json['start_time_system_s'] \n",
    "l_eye_timestamps =  l_eye_timestamps_og - pupil_recording_info_json['start_time_synced_s'] +pupil_recording_info_json['start_time_system_s'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "calculate freemocap unix timestamps (as mean of each camera's timestamp on each frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "each_cam_timestamps_list = []\n",
    "\n",
    "camera_names = [column_name for column_name in list(freemocap_unix_timestamps_dataframe.columns) if 'Cam' in column_name]\n",
    "\n",
    "for this_camera_name in camera_names:\n",
    "    each_cam_timestamps_list.append(np.array(freemocap_unix_timestamps_dataframe[this_camera_name]))\n",
    "    \n",
    "cameras_timestamp_array = np.stack(each_cam_timestamps_list,axis=1)\n",
    "cameras_timestamp_array[cameras_timestamp_array==-1]=np.nan #replace -1 with nan\n",
    "\n",
    "freemocap_timestamps = np.nanmean(cameras_timestamp_array,axis=1)\n",
    "\n",
    "freemocap_frame_durations = np.diff(freemocap_timestamps)\n",
    "freemocap_frames_per_second = np.nanmean(freemocap_frame_durations**-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "\n",
    "    timestamp_diff_on_each_frame_rel_cam0 = np.diff(cameras_timestamp_array, axis=1)\n",
    "    frame_duration = np.diff(freemocap_timestamps)\n",
    "\n",
    "    fig = plt.figure(234899234)\n",
    "    ax1 =  fig.add_subplot(411)\n",
    "    ax1.plot(cameras_timestamp_array, '.-',label='each cam')\n",
    "    ax1.plot(freemocap_timestamps, 'r-',label='freemocap_timestamps')\n",
    "    ax1.set_title('cameras_timestamps')\n",
    "    ax1.set_xlabel('frame number')\n",
    "    ax1.set_ylabel('timestamp')\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    ax2 =  fig.add_subplot(412)\n",
    "    for this_cam_num in range(timestamp_diff_on_each_frame_rel_cam0.shape[1]):\n",
    "        ax2.hist(timestamp_diff_on_each_frame_rel_cam0[:,this_cam_num], label=f'camera {this_cam_num}', alpha=0.5)\n",
    "    ax2.set_xlim(-.1,.1)\n",
    "    ax2.set_xlabel('timestamp diff on each frame (s)')\n",
    "    ax2.legend()\n",
    "\n",
    "    ax3 =  fig.add_subplot(413)\n",
    "    ax3.plot(freemocap_frame_durations, '.-',label='frame duration')\n",
    "    ax3.plot([0, len(freemocap_frame_durations)],\n",
    "            [np.nanmean(freemocap_frame_durations), np.nanmean(freemocap_frame_durations)],\n",
    "            'r-',\n",
    "            label=f'mean frame duration (ms):{str(np.nanmean(freemocap_frame_durations)*1000)[:5]}',\n",
    "            )\n",
    "    ax3.legend(loc='upper left')\n",
    "    ax3.set_xlabel('frame number')\n",
    "    ax3.set_ylabel('frame duration (s)')\n",
    "\n",
    "    ax4 =  fig.add_subplot(414)\n",
    "    ax4.hist(freemocap_frame_durations**-1, label='frame duration')\n",
    "    ax4.legend(loc='upper left')\n",
    "    ax4.set_xlabel('frame rate (frames per second')\n",
    "    ax4.set_xlim(0,50)\n",
    "    \n",
    "    plt.pause(.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'freemocap_timestamps[-1]: {freemocap_timestamps[-1]}')\n",
    "print(f'r_eye_timestamps[-1]: {r_eye_timestamps[-1]}')\n",
    "\n",
    "np.min((freemocap_timestamps[-1],r_eye_timestamps[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### align freemocap and pupil timestamps and clip the starts and ends of the various data traces so that everything covers the same timespacn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#find start and end frames shared by all datastreams\n",
    "start_time_unix = np.max((freemocap_timestamps[0],r_eye_timestamps[0], l_eye_timestamps[0]))\n",
    "end_time_unix = np.min((freemocap_timestamps[-1],r_eye_timestamps[-1], l_eye_timestamps[-1]))\n",
    "\n",
    "#freemocap\n",
    "if any(freemocap_timestamps>=start_time_unix):\n",
    "    freemocap_start = np.where(freemocap_timestamps>=start_time_unix)[0][0]\n",
    "else:\n",
    "    freemocap_start = 0\n",
    "\n",
    "if any(freemocap_timestamps<=end_time_unix):\n",
    "    freemocap_end = np.where(freemocap_timestamps<=end_time_unix)[0][-1]\n",
    "else:\n",
    "    freemocap_end = len(freemocap_timestamps)\n",
    "\n",
    "#right eye\n",
    "if any(r_eye_timestamps>=start_time_unix):\n",
    "    r_eye_start = np.where(r_eye_timestamps>=start_time_unix)[0][0]\n",
    "else:\n",
    "    r_eye_start = 0\n",
    "    \n",
    "if any(r_eye_timestamps<=end_time_unix):\n",
    "    r_eye_end = np.where(r_eye_timestamps<=end_time_unix)[0][-1]\n",
    "else:\n",
    "    r_eye_end = len(r_eye_timestamps)\n",
    "\n",
    "#left eye\n",
    "if any(l_eye_timestamps>=start_time_unix):\n",
    "    l_eye_start = np.where(l_eye_timestamps>=start_time_unix)[0][0]\n",
    "else:\n",
    "    l_eye_start = 0\n",
    "    \n",
    "if any(l_eye_timestamps<=end_time_unix):\n",
    "    l_eye_end = np.where(l_eye_timestamps<=end_time_unix)[0][-1]\n",
    "else:\n",
    "    l_eye_end = len(l_eye_timestamps)\n",
    "\n",
    "#rebase time onto freemocap's framerate (b/c it's slower than pupil) <- sloppy, assumes mocap slower than eye tracker, which is untrue for say GoPros\n",
    "new_timestamps = np.arange(start_time_unix,end_time_unix,1/freemocap_frames_per_second) \n",
    "\n",
    "\n",
    "freemocap_timestamps = freemocap_timestamps[freemocap_start:freemocap_end]\n",
    "r_eye_timestamps = r_eye_timestamps[r_eye_start:r_eye_end]\n",
    "l_eye_timestamps = l_eye_timestamps[l_eye_start:l_eye_end]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "clip out portions of each eye's data stream that correspond to the shared time period\n",
    "\n",
    "(I appear to be skiping the freemocap data, which might cause fail on other recordings?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r_eye_sphere_center_x = r_eye_sphere_center_x[r_eye_start:r_eye_end]\n",
    "r_eye_sphere_center_y = r_eye_sphere_center_y[r_eye_start:r_eye_end]\n",
    "r_eye_sphere_center_z = r_eye_sphere_center_z[r_eye_start:r_eye_end]\n",
    "\n",
    "r_eye_pupil_center_normal_x = r_eye_pupil_center_normal_x[r_eye_start:r_eye_end]\n",
    "r_eye_pupil_center_normal_y = r_eye_pupil_center_normal_y[r_eye_start:r_eye_end]\n",
    "r_eye_pupil_center_normal_z = r_eye_pupil_center_normal_z[r_eye_start:r_eye_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "l_eye_sphere_center_x = l_eye_sphere_center_x[l_eye_start:l_eye_end]\n",
    "l_eye_sphere_center_y = l_eye_sphere_center_y[l_eye_start:l_eye_end]\n",
    "l_eye_sphere_center_z = l_eye_sphere_center_z[l_eye_start:l_eye_end]\n",
    "\n",
    "l_eye_pupil_center_normal_x = l_eye_pupil_center_normal_x[l_eye_start:l_eye_end]\n",
    "l_eye_pupil_center_normal_y = l_eye_pupil_center_normal_y[l_eye_start:l_eye_end]\n",
    "l_eye_pupil_center_normal_z = l_eye_pupil_center_normal_z[l_eye_start:l_eye_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "create r_eye_gaze_xyz : the direction the eye is pointing *in head centered coordinates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r_eye_gaze_x = r_eye_pupil_center_normal_x\n",
    "r_eye_gaze_y = r_eye_pupil_center_normal_y\n",
    "r_eye_gaze_z = r_eye_pupil_center_normal_z\n",
    "\n",
    "r_eye_gaze_xyz_og = np.vstack((r_eye_gaze_x, r_eye_gaze_y, r_eye_gaze_z)).T\n",
    "\n",
    "print(f'r_eye_gaze_xyz_og.shape: {r_eye_gaze_xyz_og.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "l_eye_gaze_x = l_eye_pupil_center_normal_x\n",
    "l_eye_gaze_y = l_eye_pupil_center_normal_y\n",
    "l_eye_gaze_z = l_eye_pupil_center_normal_z\n",
    "\n",
    "l_eye_gaze_xyz_og = np.vstack((l_eye_gaze_x, l_eye_gaze_y, l_eye_gaze_z)).T\n",
    "\n",
    "print(f'l_eye_gaze_xyz_og.shape: {l_eye_gaze_xyz_og.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### resample gaze and skeleton data so that each has the same number of frames\n",
    "\n",
    "resample pupil data onto freemocap timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "r_eye_gaze_xyz = np.zeros((len(freemocap_timestamps),3))\n",
    "l_eye_gaze_xyz = np.zeros((len(freemocap_timestamps),3))\n",
    "\n",
    "for this_dimension in range(3): #loop over the X Y and Z simensions and resample to new timestamps\n",
    "    r_eye_gaze_xyz[:,this_dimension] = np.interp(freemocap_timestamps,\n",
    "                                        r_eye_timestamps,\n",
    "                                        r_eye_gaze_xyz_og[:,this_dimension])\n",
    "    l_eye_gaze_xyz[:,this_dimension] = np.interp(freemocap_timestamps,\n",
    "                                        l_eye_timestamps,\n",
    "                                        l_eye_gaze_xyz_og[:,this_dimension])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r_eye_gaze_xyz = r_eye_gaze_xyz/np.linalg.norm(r_eye_gaze_xyz,axis=1,ord=2)[:,None]\n",
    "l_eye_gaze_xyz = l_eye_gaze_xyz/np.linalg.norm(l_eye_gaze_xyz,axis=1,ord=2)[:,None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# snip off the first frame of the freemocap data becuase there is a -> BUG <- such that there are one fewer timestamp than there are recorded frames. \n",
    "\n",
    "V V V V V V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if r_eye_gaze_xyz.shape[0] != mediapipe_skeleton_fr_mar_xyz.shape[0]:\n",
    "    mediapipe_skeleton_fr_mar_xyz = np.delete(mediapipe_skeleton_fr_mar_xyz, 0, axis=0)\n",
    "    mediapipe_head_rotation_matricies_fr_row_col = np.delete(mediapipe_head_rotation_matricies_fr_row_col, 0, axis=0)\n",
    "# DOESN'T BOTHER ME AT ALL HAHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "These should all have the exact same number of frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'r_eye_gaze_xyz.shape: {r_eye_gaze_xyz.shape}')\n",
    "print(f'l_eye_gaze_xyz.shape: {l_eye_gaze_xyz.shape}')\n",
    "print(f'mediapipe_skeleton_fr_mar_xyz.shape: {mediapipe_skeleton_fr_mar_xyz.shape}')\n",
    "print(f'mediapipe_head_rotation_matricies_fr_row_col.shape: {mediapipe_head_rotation_matricies_fr_row_col.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    fig = plt.figure(num=65341,figsize=(10,20))\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.plot(freemocap_timestamps, r_eye_gaze_xyz[:,0], '.-', label='r_eye_gaze_x')\n",
    "    ax1.plot(freemocap_timestamps, r_eye_gaze_xyz[:,1], '.-', label='r_eye_gaze_y')\n",
    "    ax1.plot(freemocap_timestamps, r_eye_gaze_xyz[:,2], '.-', label='r_eye_gaze_z')\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    ax2 = fig.add_subplot(212)\n",
    "    ax2.plot(freemocap_timestamps, l_eye_gaze_xyz[:,0], '.-', label='_eye_gaze_x')\n",
    "    ax2.plot(freemocap_timestamps, l_eye_gaze_xyz[:,1], '.-', label='_eye_gaze_y')\n",
    "    ax2.plot(freemocap_timestamps, l_eye_gaze_xyz[:,2], '.-', label='_eye_gaze_z')\n",
    "    ax2.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "normalize gaze vector to unit length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "save out `npy` of gaze_xyz data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Smooth a bit with savitsky golay filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "smoothWinLength = 5\n",
    "smoothOrder = 3\n",
    "for dim in range(r_eye_gaze_xyz.shape[1]):\n",
    "        r_eye_gaze_xyz[:,dim] = savgol_filter(r_eye_gaze_xyz[:,dim], smoothWinLength, smoothOrder)\n",
    "        l_eye_gaze_xyz[:,dim] = savgol_filter(l_eye_gaze_xyz[:,dim], smoothWinLength, smoothOrder)\n",
    "\n",
    "\n",
    "# #reorient gaze (I think because it comes in in image coordiates? not really sure )\n",
    "# r_eye_gaze_xyz[:,1] = -r_eye_gaze_xyz[:,1]\n",
    "# r_eye_gaze_xyz[:,(0,2)] = r_eye_gaze_xyz[:,(2,0)]\n",
    "\n",
    "# l_eye_gaze_xyz[:,1] = -l_eye_gaze_xyz[:,1]\n",
    "# l_eye_gaze_xyz[:,(0,2)] = l_eye_gaze_xyz[:,(2,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r_gaze_xyz_npy_save_path = pupil_data_exports_path / 'right_eye_gaze_xyz_synchronized_w_freemocap_uncalibrated.npy'\n",
    "np.save(r_gaze_xyz_npy_save_path, r_eye_gaze_xyz)\n",
    "\n",
    "l_gaze_xyz_npy_save_path = pupil_data_exports_path / 'left_eye_gaze_xyz_synchronized_w_freemocap_uncalibrated.npy'\n",
    "np.save(l_gaze_xyz_npy_save_path, l_eye_gaze_xyz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# VOR Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# prep data for VOR calibration\n",
    "\n",
    "we'll be finding a rotational offset such that gaze_xyz rotated-by-the offset-then-rotated-by-head-orientation will align with the fixation point\n",
    "\n",
    " so we want to put the fixation point (in this case the right index finger in a eyeball-centered reference frame (i.e. where `r_eye_xyz` is at `(0,0,0)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vor_frame_start =1000\n",
    "vor_frame_end = 1400\n",
    "\n",
    "right_index_fingertip_idx = 41 # pretty sure this is right?\n",
    "r_eye_idx = 5\n",
    "\n",
    "fixation_point_xyz = np.squeeze(mediapipe_skeleton_fr_mar_xyz[:, right_index_fingertip_idx, :])\n",
    "r_eyeball_center_xyz = np.squeeze(mediapipe_skeleton_fr_mar_xyz[:, r_eye_idx, :])\n",
    "#make sure everyone is the right size and shape\n",
    "print(f'head_rotation_martices_fr_row_col.shape: {mediapipe_head_rotation_matricies_fr_row_col.shape}')\n",
    "print(f'r_eye_gaze_xyz.shape: {r_eye_gaze_xyz.shape}')\n",
    "print(f'fixation_point_xyz.shape: {fixation_point_xyz.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fixation_point_during_vor_xyz = mediapipe_skeleton_fr_mar_xyz[vor_frame_start:vor_frame_end, right_index_fingertip_idx, :]\n",
    "r_eyeball_center_during_vor_xyz = mediapipe_skeleton_fr_mar_xyz[vor_frame_start:vor_frame_end, r_eye_idx, :]\n",
    "\n",
    "fixation_point_in_r_eyeball_coordinates_fr_xyz = r_eyeball_center_during_vor_xyz - fixation_point_during_vor_xyz #Subtract the-thing-that-will-be-at-origin from the-other-things to put other-things in ## thing-that-will-be-at-origin-centered-reference-frame\n",
    "fixation_point_distance_xyz = np.squeeze(np.linalg.norm(fixation_point_in_r_eyeball_coordinates_fr_xyz,axis=1,ord=2)[:,None])\n",
    "\n",
    "\n",
    "\n",
    "r_gaze_during_vor_fr_xyz = r_eye_gaze_xyz[vor_frame_start:vor_frame_end]\n",
    "r_gaze_during_vor_fr_xyz[:,0] = r_gaze_during_vor_fr_xyz[:,0] * fixation_point_distance_xyz #scale gaze vector to reach fixation point\n",
    "r_gaze_during_vor_fr_xyz[:,1] = r_gaze_during_vor_fr_xyz[:,1] * fixation_point_distance_xyz #scale gaze vector to reach fixation point\n",
    "r_gaze_during_vor_fr_xyz[:,2] = r_gaze_during_vor_fr_xyz[:,2] * fixation_point_distance_xyz #scale gaze vector to reach fixation point\n",
    "r_gaze_during_vor_fr_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "head_rotation_matrices_during_vor_fr_row_col = mediapipe_head_rotation_matricies_fr_row_col[vor_frame_start:vor_frame_end, :, :]\n",
    "\n",
    "#make sure everyone is the right size and shape\n",
    "print(f'head_rotation_matrices_during_vor_fr_row_col.shape: {head_rotation_matrices_during_vor_fr_row_col.shape}')\n",
    "print(f'r_gaze_during_vor_xyz.shape: {r_gaze_during_vor_fr_xyz.shape}')\n",
    "print(f'fixation_point_in_r_eyeball_coordinates_xyz.shape: {fixation_point_in_r_eyeball_coordinates_fr_xyz.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "put mediapipe skel into eyeball centered coordinates (for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "skel_during_vor_fr_mar_dim = mediapipe_skeleton_fr_mar_xyz[vor_frame_start:vor_frame_end,:,:]\n",
    "\n",
    "for this_marker_number in range(skel_during_vor_fr_mar_dim.shape[1]):\n",
    "    skel_during_vor_fr_mar_dim[:,this_marker_number,:] = r_eyeball_center_during_vor_xyz - skel_during_vor_fr_mar_dim[:,this_marker_number,:]\n",
    "\n",
    "\n",
    "print(f'skel_during_vor_fr_mar_dim.shape: {skel_during_vor_fr_mar_dim.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# define error functions and run optimization\n",
    "\n",
    "according to  lines  58:68 of - [https://github.com/trentwirth/ARGP_Matlab_LaserSkeleton/blob/main/Toolbox/vorPupilAlignErrFun_eyeCam.m](https://github.com/trentwirth/ARGP_Matlab_LaserSkeleton/blob/main/Toolbox/vorPupilAlignErrFun_eyeCam.m)\n",
    "```\n",
    "\n",
    "%%\n",
    "%%%%%%% This part's important - Rotate gaze vector by [this guess at the proper alignment matrix], prior to resituating  the origin on on the eyeball\n",
    "%%%%\n",
    "\n",
    "\n",
    "for rr = 1:length(gazeXYZ)\n",
    "    \n",
    "    thisET_frame_unrot = camRotMatGuess * [gazeXYZ(rr,1); gazeXYZ(rr,2); gazeXYZ(rr,3)];\n",
    "    thisETframe = headRotMat_row_col_fr(:,:,rr) * thisET_frame_unrot;\n",
    "    \n",
    "    headOrVec(rr,:) =     headRotMat_row_col_fr(:,:,rr) * [2e3; 0;0];\n",
    "    \n",
    "    gazeXYZ(rr,:) = thisETframe;\n",
    "    \n",
    "end\n",
    "\n",
    "```\n",
    "\n",
    "we want to rotate by rotation_guess THEN by head rotation \n",
    "\n",
    "(which makes sense, since we're using the optimizer to find the rotational offset between the eye camera reference frame and the eye-in-head reference frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### optimization error animation function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if debug:\n",
    "    def plot_optimization_error(error,gaze_xyz, gaze_rotated_by_guess_then_head_rotation_xyz, mean_fixation_point_xyz, skel_during_vor_fr_mar_dim):\n",
    "        figure_number=13451\n",
    "\n",
    "        if not plt.fignum_exists(figure_number):\n",
    "            fig = plt.figure(figure_number)\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "        else:\n",
    "            fig = plt.gcf()\n",
    "            ax = plt.gca()\n",
    "\n",
    "\n",
    "        fig.suptitle(f'error: {error}')\n",
    "        ax_range = 1e3\n",
    "        ax.clear() \n",
    "\n",
    "        ax.plot(0,0,0, 'mo',label='origin')\n",
    "\n",
    "        ax.plot(gaze_xyz[:,0],\n",
    "                gaze_xyz[:,1], \n",
    "                gaze_xyz[:,2],  'k-o',label='original gaze xyz')\n",
    "\n",
    "        gaze_rot_xyz  =np.array(gaze_rotated_by_guess_then_head_rotation_xyz)\n",
    "        ax.plot(gaze_rot_xyz[:,0],\n",
    "                gaze_rot_xyz[:,1], \n",
    "                gaze_rot_xyz[:,2],  'r-o',label='gaze_rotated_by_guess_then_head_rotation_xyz')\n",
    "\n",
    "        ax.plot(mean_fixation_point_xyz[0],\n",
    "                mean_fixation_point_xyz[1], \n",
    "                mean_fixation_point_xyz[2],  'b-o',label='mean_fixation_point_xyz')\n",
    "\n",
    "        ax.set_xlim([-ax_range, ax_range])\n",
    "        ax.set_ylim([-ax_range, ax_range])\n",
    "        ax.set_zlim([-ax_range, ax_range])\n",
    "        ax.legend()\n",
    "        plt.pause(.01)\n",
    "\n",
    "\n",
    "\n",
    "def get_error_between_two_rotation_matricies(euler_angle_guess,\n",
    "                                             gaze_xyz,\n",
    "                                             fixation_point_in_eye_coordinates_xyz,\n",
    "                                             head_rotation_maticies_fr_row_col,\n",
    "                                             skel_during_vor_fr_mar_dim):\n",
    "    #convert euler angles to rotation matrix\n",
    "    rotation_matrix_guess = Rotation.from_euler('XYZ',euler_angle_guess).as_matrix()\n",
    "\n",
    "    #rotate gaze by rotation guess\n",
    "    gaze_rotated_by_guess = [rotation_matrix_guess @ gaze_xyz[this_frame_number,:] for this_frame_number in range(gaze_xyz.shape[0])]\n",
    "\n",
    "    #...then rotate THAT by head_rotation matrix\n",
    "    gaze_rotated_by_guess_then_head_rotation_xyz =[head_rotation_maticies_fr_row_col[this_frame_number,:,:] @ gaze_rotated_by_guess[this_frame_number]\n",
    "                                                     for this_frame_number in range(gaze_xyz.shape[0])]\n",
    "\n",
    "    mean_fixation_point_xyz = np.mean(fixation_point_in_eye_coordinates_xyz, axis=0)\n",
    "    #define error as difference between the fixation point and that rotated gaze estimate (these are both normalized, I think)\n",
    "    error_per_frame = gaze_rotated_by_guess_then_head_rotation_xyz - mean_fixation_point_xyz\n",
    "    error = np.nanmean(np.nansum(error_per_frame**2)/error_per_frame.shape[0])\n",
    "    \n",
    "    plot_optimization_error(error,gaze_xyz, gaze_rotated_by_guess_then_head_rotation_xyz, mean_fixation_point_xyz, skel_during_vor_fr_mar_dim)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "def get_optimal_rotation_matrix_to_align_gaze_with_target(gaze_xyz,\n",
    "                                                          fixation_point_in_eye_coordinates_xyz,\n",
    "                                                          head_rotation_matricies_fr_row_col,\n",
    "                                                          skel_during_vor_fr_mar_dim):\n",
    "    euler_angles = optimize.least_squares(get_error_between_two_rotation_matricies,\n",
    "                                    [0,0,0],\n",
    "                                    args=(gaze_xyz,fixation_point_in_eye_coordinates_xyz, head_rotation_matricies_fr_row_col, skel_during_vor_fr_mar_dim),\n",
    "                                    gtol=1e-10,\n",
    "                                    verbose=2).x\n",
    "    return Rotation.from_euler('XYZ',euler_angles).as_matrix()\n",
    "\n",
    "\n",
    "######################################\n",
    "\n",
    "\n",
    "rotation_matrix_to_align_pupil_data_to_eye_in_head_coordinates = get_optimal_rotation_matrix_to_align_gaze_with_target(r_gaze_during_vor_fr_xyz,\n",
    "                                                                                fixation_point_in_r_eyeball_coordinates_fr_xyz,\n",
    "                                                                                head_rotation_matrices_during_vor_fr_row_col,\n",
    "                                                                                skel_during_vor_fr_mar_dim)\n",
    "\n",
    "r_eye_gaze_xyz_calibrated = [rotation_matrix_to_align_pupil_data_to_eye_in_head_coordinates @ r_eye_gaze_xyz[this_frame_number,:] for this_frame_number in range(r_eye_gaze_xyz.shape[0])]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gaze_xyz_npy_save_path = pupil_data_exports_path / 'right_eye_gaze_xyz.npy'\n",
    "np.save(gaze_xyz_npy_save_path, r_eye_gaze_xyz_calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(r_eye_gaze_xyz.shape[0]), y=r_eye_gaze_xyz[:,0], mode='lines+markers'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(r_eye_gaze_xyz.shape[0]), y=r_eye_gaze_xyz[:,1], mode='lines+markers'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(r_eye_gaze_xyz.shape[0]), y=r_eye_gaze_xyz[:,2], mode='lines+markers'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_path = Path('C:/Users/jonma/Dropbox/FreeMoCapProject/FreeMocap_Data/')\n",
    "session_path = data_path / 'sesh_2022-02-15_11_54_28_pupil_maybe'\n",
    "\n",
    "qt_gl_laser_skeleton = QT_GL_LaserSkeleton(session_path)\n",
    "qt_gl_laser_skeleton.start_animation()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ef2e72e5b895021b427c707c9f05b4880b5a5a00e886b84de197a42e54c7f32"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('humon-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
